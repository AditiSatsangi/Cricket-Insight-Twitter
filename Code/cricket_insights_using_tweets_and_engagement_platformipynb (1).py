# -*- coding: utf-8 -*-
"""Cricket Insights using tweets and Engagement Platformipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lKKcXGqDfb8cKD2pT5As_gv3doqmCzSe

# Importing Libraries
"""

import pandas as pd

from textblob import TextBlob
import matplotlib.pyplot as plt
from collections import Counter
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""# Loading Dataset"""

from google.colab import drive
drive.mount('/content/drive')

# Load the dataset containing Cricket Tweets
#df = pd.read_csv('cricket_tweets.csv.zip.zip')
df = pd.read_csv('Data.csv')

"""# Explore Dataset"""

print(df.head())

df.shape

df.columns

df.info()

"""# Data Cleaning"""

# Select the relevant columns from the dataset
selected_columns = ['id','user_name','user_location','user_description','user_followers','date', 'text','hashtags', 'source','retweets','favorites']
df_selected = df[selected_columns]

# Perform analysis on the selected data
# TODO: Perform desired analysis on the dataset

# Print the first few rows of the selected data
print(df_selected.head())

df['user_location'].value_counts()

# Display the first few rows of the selected data
print("First few rows of the selected data:")
print(df_selected.head())

"""# Labelling data"""

from textblob import TextBlob
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# Extract the text feature
tweet = df['text']
# Perform sentiment analysis and assign labels
labels = []
for text in tweet:
    blob = TextBlob(text)
    sentiment = blob.sentiment.polarity
    label = 1 if sentiment > 0 else 0
    labels.append(label)

# Add the labels to the DataFrame
df['label'] = labels

# Print the text feature and labels
print("Text Feature:\n")
print(tweet)
print("\nLabels:\n")
df['label'] .head()

"""# SENTIMENT ANALYSIS"""

# Perform sentiment analysis on the 'text' column
df_selected['sentiment'] = df_selected['text'].apply(lambda x: TextBlob(x).sentiment.polarity)

# Print the average sentiment score
avg_sentiment = df_selected['sentiment'].mean()
print("Average sentiment score:", avg_sentiment)

"""**PLOT FOR SENTIMENT SCORE**

"""

plt.figure(figsize=(8, 6))
plt.bar(df_selected['sentiment'].value_counts().index, df_selected['sentiment'].value_counts().values)
plt.xlabel('Sentiment Score')
plt.ylabel('Count')
plt.title('Sentiment Analysis')
plt.show()

""" **HASHTAG ANALYSIS**"""

# Select the 'hashtags' column and drop missing values
hashtags = df['hashtags'].dropna()

#Split the hashtags and convert to lowercase
hashtags = hashtags.str.lower().str.split(',')

# Flatten the list of hashtags
hashtags = [tag for sublist in hashtags if isinstance(sublist, list) for tag in sublist]

# Count the frequency of each hashtag
hashtag_counts = Counter(hashtags)

# Print the top 10 most common hashtags
top_hashtags = hashtag_counts.most_common(10)
for hashtag, count in top_hashtags:
    print(hashtag, count)

# Generate word cloud of hashtags
all_hashtags = ' '.join(hashtags)
wordcloud = WordCloud(width=800, height=400, background_color='BLACK').generate(all_hashtags)

# Plot the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Tweets Hashtag Analysis')
plt.show()

"""# USER ENGAGEMENT ANALYSIS"""

# Calculate the average retweet and favorite counts
avg_retweet= df['retweets'].mean();
avg_favourite= df['favorites'].mean();
print("Averge Retweets Count : ", avg_retweet);
print("Averge Favourite Count : ", avg_favourite);

plt.figure(figsize=(8, 6))
plt.bar(['Retweets', 'Favorites'], [avg_retweet, avg_favourite])
plt.ylabel('Count')
plt.title('Average Retweets and Favorites')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the preprocessed tweet data with user engagement metrics
#tweet_data = pd.read_csv('tweet_data.csv')  # Replace 'tweet_data.csv' with your file path

# Convert the timestamp column to datetime format
df['date'] = pd.to_datetime(df['date'])

# Group the data by timestamp and calculate the sum of retweet counts for each timestamp
engagement_data = df.groupby(pd.Grouper(key='date', freq='D')).sum()['retweets']

# Plot the user engagement metrics over time
plt.figure(figsize=(10, 6))
engagement_data.plot(kind='line', marker='o')
plt.xlabel('Date')
plt.ylabel('Retweet Count')
plt.title('User Engagement Metrics: Retweet Counts over Time')
plt.grid(True)
plt.show()

"""**USER LOCATION ANALYSIS**"""

# Extract the top 5 most common user locations
top_locations = df_selected['user_location'].value_counts().head(5)
print("Top 5 user locations:")
print(top_locations)

# Plot the top user locations
plt.figure(figsize=(10,6))
colors=['orange','black','black','black','black']
top_locations.plot(kind='bar', color= colors)
plt.xlabel('User Location')
plt.ylabel('Count')
plt.title('Top User Locations')
plt.xticks(rotation= 45)
plt.show()

"""**SOURCE ANALYSIS**"""

# Count the number of tweets from each source
SOURCE_COUNTS= df_selected['source'].value_counts()
print("Tweet source distribution:")
print(SOURCE_COUNTS)

# Plot the top user locations
top_sources = SOURCE_COUNTS[:5]
plt.figure(figsize=(10,6))
colors=['green','yellow','blue','red','pink']
top_sources .plot(kind='bar', color= colors)
plt.xlabel('Tweet Sources')
plt.ylabel('Count')
plt.title('Tweet Source Distribution')
plt.xticks(rotation= 0)
plt.show()

"""# Training Model

**Using Random Forest Classification**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
# Prepare the data
X = df['id'].values.reshape(-1, 1)  # Reshape the user_info column to a 2D array
y = df['retweets'].values
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=43)

# Initialize the Random Forest classifier
clf = RandomForestClassifier()

# Train the classifier
clf.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf.predict(X_test)

"""Evaluate Accuracy"""

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""**Using** **Logistic** **Regression**"""

# Preprocess the tweets
preprocessed_tweets = [TextBlob(tweet).lower() for tweet in tweet]

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(preprocessed_tweets, labels, test_size=0.001, random_state=42)

# Convert TextBlob objects back to strings
X_train_strings = [str(tweet.raw) for tweet in X_train]
X_test_strings = [str(tweet.raw) for tweet in X_test]

# Vectorize the tweets using CountVectorizer
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train_strings)
X_test_vectorized = vectorizer.transform(X_test_strings)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

"""# Prediction and Accuracy"""

# Predict the labels for the test set
y_pred = model.predict(X_test_vectorized)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)