# -*- coding: utf-8 -*-
"""Cricket Insights using tweets and Engagement Platformipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lKKcXGqDfb8cKD2pT5As_gv3doqmCzSe

**IMPORTING** **LIBRARIES**
"""

import pandas as pd

from textblob import TextBlob
import matplotlib.pyplot as plt
from collections import Counter
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""**Load** **Dataset**"""

# Load the dataset containing Cricket Tweets
df = pd.read_csv('cricket_tweets.csv')

print(df.head())

"""**Data** **Cleaning**"""

# Select the relevant columns from the dataset
selected_columns = ['id','user_location','date', 'text','hashtags', 'source','retweets','favorites']
df_selected = df[selected_columns]

# Perform analysis on the selected data
# TODO: Perform desired analysis on the dataset

# Print the first few rows of the selected data
print(df_selected.head())

df.shape

df.columns

df.info()

df['user_location'].value_counts()

#  Perform analysis on the selected data
# TODO: Perform your desired analysis on the dataset
# Example: Calculate the average number of retweets
avg_retweets = df_selected['retweets'].mean()
print("Average number of retweets:", avg_retweets)

# Display the first few rows of the selected data
print("First few rows of the selected data:")
print(df_selected.head())

"""**Labelling** **data**"""

from textblob import TextBlob
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# Extract the text feature
tweet = df['text']
# Perform sentiment analysis and assign labels
labels = []
for text in tweet:
    blob = TextBlob(text)
    sentiment = blob.sentiment.polarity
    label = 1 if sentiment > 0 else 0
    labels.append(label)

# Add the labels to the DataFrame
df['label'] = labels

# Print the text feature and labels
print("Text Feature:\n")
print(tweet)
print("\nLabels:\n")
print(labels)

"""**SENTIMENT ANALYSIS**"""

# Perform sentiment analysis on the 'text' column
df_selected['sentiment'] = df_selected['text'].apply(lambda x: TextBlob(x).sentiment.polarity)

# Print the average sentiment score
avg_sentiment = df_selected['sentiment'].mean()
print("Average sentiment score:", avg_sentiment)

"""**PLOT FOR SENTIMENT SCORE**

"""

plt.figure(figsize=(8, 6))
plt.bar(df_selected['sentiment'].value_counts().index, df_selected['sentiment'].value_counts().values)
plt.xlabel('Sentiment Score')
plt.ylabel('Count')
plt.title('Sentiment Analysis')
plt.show()

"""**HASHTAGS** **ANALYSIS**"""

# Select the 'hashtags' column and drop missing values
hashtags = df['hashtags'].dropna()

#Split the hashtags and convert to lowercase
hashtags = hashtags.str.lower().str.split(',')

# Flatten the list of hashtags
hashtags = [tag for sublist in hashtags if isinstance(sublist, list) for tag in sublist]

# Count the frequency of each hashtag
hashtag_counts = Counter(hashtags)

# Print the top 10 most common hashtags
top_hashtags = hashtag_counts.most_common(10)
for hashtag, count in top_hashtags:
    print(hashtag, count)

# Generate word cloud of hashtags
all_hashtags = ' '.join(hashtags)
wordcloud = WordCloud(width=800, height=400, background_color='BLACK').generate(all_hashtags)

# Plot the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Tweets Hashtag Analysis')
plt.show()

"""**USER ENGAGEMENT ANALYSIS**"""

# Calculate the average retweet and favorite counts
avg_retweet= df['retweets'].mean();
avg_favourite= df['favorites'].mean();
print("Averge Retweets Count : ", avg_retweet);
print("Averge Favourite Count : ", avg_favourite);

plt.figure(figsize=(8, 6))
plt.bar(['Retweets', 'Favorites'], [avg_retweet, avg_favourite])
plt.ylabel('Count')
plt.title('Average Retweets and Favorites')
plt.show()

"""**USER LOCATION ANALYSIS**"""

# Extract the top 5 most common user locations
top_locations = df_selected['user_location'].value_counts().head(5)
print("Top 5 user locations:")
print(top_locations)

# Plot the top user locations
plt.figure(figsize=(10,6))
colors=['orange','green','blue','yellow','brown']
top_locations.plot(kind='bar', color= colors)
plt.xlabel('User Location')
plt.ylabel('Count')
plt.title('Top User Locations')
plt.xticks(rotation= 45)
plt.show()

"""**SOURCE ANALYSIS**"""

# Count the number of tweets from each source
SOURCE_COUNTS= df_selected['source'].value_counts()
print("Tweet source distribution:")
print(SOURCE_COUNTS)

# Plot the top user locations
top_sources = SOURCE_COUNTS[:5]
plt.figure(figsize=(10,6))
colors=['green','yellow','blue','red','pink']
top_sources .plot(kind='bar', color= colors)
plt.xlabel('Tweet Sources')
plt.ylabel('Count')
plt.title('Tweet Source Distribution')
plt.xticks(rotation= 0)
plt.show()

"""**TIME BASED ANALYSIS**"""

# Convert the 'timestamp' column to datetime format
df_selected['date'] = pd.to_datetime(df_selected['date'])

# Extract the day of the week from the timestamp
df_selected['day_of_week']= df_selected['date'].dt.day_name()

# Count the number of tweets on each day of the week
day_counts = df_selected['day_of_week'].value_counts()
print("Tweet count by day of the week:")
print(day_counts)

# Plot the user verification distribution
plt.figure(figsize=(8, 6))
plt.pie(day_counts, labels=day_counts.index, autopct='%1.1f%%')
plt.title('User engagement Days')
plt.show()

"""**Using** **Logistic** **Regression**"""

# Preprocess the tweets
preprocessed_tweets = [TextBlob(tweet).lower() for tweet in tweet]

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(preprocessed_tweets, labels, test_size=0.001, random_state=42)

# Convert TextBlob objects back to strings
X_train_strings = [str(tweet.raw) for tweet in X_train]
X_test_strings = [str(tweet.raw) for tweet in X_test]

# Vectorize the tweets using CountVectorizer
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train_strings)
X_test_vectorized = vectorizer.transform(X_test_strings)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

"""**Prediction** **and** **Accuracy**"""

# Predict the labels for the test set
y_pred = model.predict(X_test_vectorized)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import pickle
with open('sentiment_analysis_model.pkl', 'wb') as file:
    pickle.dump(model, file)

with open('sentiment_analysis_model.pkl', 'rb') as file:
    model = pickle.load(file)

